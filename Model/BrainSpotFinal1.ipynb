{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import and lode modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Root=\"/content/drive/MyDrive/NewDataset3/Brain Tumour1\"\n",
    "number_of_images={}\n",
    "for dir in os.listdir(Root):\n",
    "  number_of_images[dir]=len(os.listdir(os.path.join(Root,dir)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_images.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dict_items([('Non tumour', 2075), ('Tumour', 1687)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data -> 70% for train, 15% for validation, 15% for testing\n",
    "\n",
    "def dataFolder(p,split):\n",
    "\n",
    "  if not os.path.exists(\"./\"+p):\n",
    "    os.mkdir(\"./\"+p)\n",
    "\n",
    "    for dir in os.listdir(Root):\n",
    "      os.makedirs(\"./\"+p+\"/\"+dir)\n",
    "\n",
    "      for img in np.random.choice(a=os.listdir(os.path.join(Root,dir)),\n",
    "                                  size=(math.floor(split*number_of_images[dir])-5),\n",
    "                                  replace=False):\n",
    "\n",
    "        O=os.path.join(Root,dir,img)\n",
    "        D=os.path.join(\"./\"+p,dir)\n",
    "        shutil.copy(O,D)\n",
    "        #os.remove(O)\n",
    "\n",
    "  else:\n",
    "    print( f\"{p}folder exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolder(\"train\",0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolder(\"validation\",0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolder(\"test\",0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model build\n",
    "\n",
    "from keras.layers import Conv2D, MaxPool2D,Dropout,Flatten,Dense,BatchNormalization,GlobalAvgPool2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#CNN model\n",
    "\n",
    "from keras.models import Sequential  # Make sure to import Sequential with an uppercase \"S\"\n",
    "from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3), padding='same'))\n",
    "model.add(Conv2D(filters=36, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(GlobalAvgPool2D())  # Add Global Average Pooling layer\n",
    "\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    " Layer (type)                Output Shape              Param #   \n",
    "=================================================================\n",
    " conv2d (Conv2D)             (None, 224, 224, 16)      448       \n",
    "                                                                 \n",
    " conv2d_1 (Conv2D)           (None, 222, 222, 36)      5220      \n",
    "                                                                 \n",
    " max_pooling2d (MaxPooling2D  (None, 111, 111, 36)     0         \n",
    " )                                                               \n",
    "                                                                 \n",
    " conv2d_2 (Conv2D)           (None, 109, 109, 64)      20800     \n",
    "                                                                 \n",
    " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
    " 2D)                                                             \n",
    "                                                                 \n",
    " conv2d_3 (Conv2D)           (None, 52, 52, 128)       73856     \n",
    "                                                                 \n",
    " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
    " 2D)                                                             \n",
    "                                                                 \n",
    " global_average_pooling2d (G  (None, 128)              0         \n",
    " lobalAveragePooling2D)                                          \n",
    "                                                                 \n",
    " dropout (Dropout)           (None, 128)               0         \n",
    "...\n",
    "Total params: 116,965\n",
    "Trainable params: 116,965\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=keras.losses.binary_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use data generator\n",
    "\n",
    "def preImage1(path):\n",
    "  \"\"\"\n",
    "  input:path\n",
    "  output:pre proccessed images\n",
    "  \"\"\"\n",
    "  image_data=ImageDataGenerator(zoom_range=0.2,shear_range=0.2,rescale=1/255,horizontal_flip=True)  #data augmentation\n",
    "\n",
    "  image=image_data.flow_from_directory(directory=path,target_size=(244,244),batch_size=32,class_mode='binary')\n",
    "\n",
    "  return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.util.compat import path_to_str\n",
    "path=\"/content/train\"\n",
    "\n",
    "train_data=preImage1(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use data generator\n",
    "\n",
    "def preImage2(path):\n",
    "  \"\"\"\n",
    "  input:path\n",
    "  output:pre proccessed images\n",
    "  \"\"\"\n",
    "  image_data=ImageDataGenerator(rescale=1/255)#no data augmentation in testing\n",
    "\n",
    "  image=image_data.flow_from_directory(directory=path,target_size=(244,244),batch_size=32,class_mode='binary')\n",
    "\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/content/test\"\n",
    "\n",
    "test_data=preImage2(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found 554 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/content/validation\"\n",
    "\n",
    "val_data=preImage2(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found 554 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early stopping and model check point\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "#early stopping\n",
    "\n",
    "es=EarlyStopping(monitor=\"val_accuracy\",min_delta=0.01,patience=12,verbose=1,mode='auto')\n",
    "\n",
    "#model checkpoint\n",
    "\n",
    "\n",
    "mc=ModelCheckpoint(monitor=\"val_accuracy\",filepath=\"./bestmodel.h5\",verbose=1,save_best=True,mode='auto')\n",
    "\n",
    "cd=[es,mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model training\n",
    "\n",
    "hs=model.fit_generator(generator=train_data,\n",
    "                       steps_per_epoch=8,\n",
    "                       epochs=30,\n",
    "                       verbose=1,\n",
    "                       validation_data=val_data,\n",
    "                       validation_steps=16,\n",
    "                       callbacks=cd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model graphical interpretation\n",
    "\n",
    "h=hs.history\n",
    "h.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(h['accuracy'])\n",
    "\n",
    "plt.plot(h['val_accuracy'],c='red')\n",
    "\n",
    "plt.title('Accuracy vs Validation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(h['loss'])\n",
    "\n",
    "plt.plot(h['val_loss'],c='red')\n",
    "\n",
    "plt.title('Loss vs Validation Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
